| Metric/Technique | What It Measures | Range | Strengths | Weaknesses | When to Use | Simple Math |
|------------------|------------------|-------|-----------|------------|-------------|-------------|
| **Silhouette Score** (Internal Clustering) | How close points are to their own cluster vs. other clusters (tightness vs. separation) | -1 to 1 (1 = great, 0 = on boundaries, -1 = wrong clusters) | Easy to interpret, balances tightness and separation, visual plots show per-point quality | Can be misleading for non-spherical clusters | To check if clusters are well-defined and separated | 1. A = Average distance to points in same cluster<br>2. B = Average distance to points in nearest other cluster<br>3. Score = (B - A) / (Bigger of A or B)<br>4. Silhouette Score = Average of all point scores |
| **Davies-Bouldin Index** (Internal Clustering) | How tight each cluster is compared to its distance from other clusters | 0 to infinity (lower is better, 0 = perfect) | Measures both compactness and separation, simple number | Sensitive to cluster shape, less intuitive than silhouette | To quantify how compact and distinct clusters are | 1. S = Average distance within a cluster<br>2. D = Distance between two clusters’ centers<br>3. Ratio = (S1 + S2) / D for each pair of clusters<br>4. DB Index = Average of highest ratios per cluster |
| **Inertia** (Internal Clustering, K-Means) | Total distance from points to their cluster’s center in k-means | 0 to infinity (lower is better) | Simple measure of how tight clusters are | Lower with more clusters, so can’t be used alone (risk of overfitting) | To check cluster compactness in k-means, with other metrics | 1. Distance = (Point - Cluster Center) * (Point - Cluster Center)<br>2. Inertia = Sum of Distance for all points |
| **Adjusted Rand Index (ARI)** (External Clustering) | How similar clusters are to true labels, adjusted for random matches | -1 to 1 (1 = perfect, 0 = random, negative = worse than random) | Robust to number of clusters, corrects for chance | Needs true labels, which are rare in unsupervised learning | When you have true labels to check cluster accuracy | 1. Count pairs of points in same/different clusters and labels<br>2. ARI = (Correct pairs - Expected random pairs) / Total pairs |
| **Normalized Mutual Information (NMI)** (External Clustering) | How much cluster assignments reveal about true labels | 0 to 1 (1 = perfect, 0 = no shared info) | Measures shared information, works with different cluster counts | Needs true labels, less intuitive than ARI | To check how much clusters align with true categories | 1. Info = How much clusters and labels overlap<br>2. NMI = Info / (Average of cluster and label info) |
| **Fowlkes-Mallows Index (FMI)** (External Clustering) | Balance of precision (correct groupings) and recall (capturing all points of a class) | 0 to 1 (higher is better) | Balances accuracy and completeness, like classification | Needs true labels, can be complex to interpret | When you want to check both accuracy and completeness of clusters | 1. Precision = Correct pairs in same cluster / Total pairs in clusters<br>2. Recall = Correct pairs in same cluster / Total pairs in labels<br>3. FMI = Square Root of (Precision * Recall) |
| **Explained Variance Ratio** (Dimensionality Reduction, PCA) | How much of data’s variation is kept in reduced dimensions | 0 to 1 per component (sum ≤ 1) | Shows how much information is retained, easy to visualize in bar plots | Only for PCA, doesn’t measure data relationships | To decide how many PCA components to keep | 1. Variance = How much each component explains<br>2. Total Variance = Sum of all variances<br>3. Ratio = Variance / Total Variance per component |
| **Reconstruction Error** (Dimensionality Reduction) | How well reduced data can rebuild the original data | 0 to infinity (lower is better, 0 = perfect) | Quantifies information loss, applies to many methods | Hard to interpret without context, varies by method | To check if reduced data retains original info | 1. Reconstruct = Build original data from reduced data<br>2. Error = (Original - Reconstruct) * (Original - Reconstruct)<br>3. Total Error = Sum of Error for all points |
| **Neighborhood Preservation** (Dimensionality Reduction, t-SNE/UMAP) | If nearby points in original data stay nearby in reduced data | No fixed range (higher is better, method-specific) | Ensures meaningful relationships are kept, key for visualization | Hard to quantify, depends on method (e.g., t-SNE, UMAP) | To check if reduced data keeps original point relationships | 1. Original Neighbors = Count nearby points in high dimensions<br>2. Reduced Neighbors = Count nearby points in low dimensions<br>3. Preservation = Compare Original vs. Reduced Neighbors |